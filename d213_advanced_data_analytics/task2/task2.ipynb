{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140c102b-b0b8-4338-baff-c18c78614882",
   "metadata": {},
   "source": [
    "# D213 Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114786c6-c445-4707-b2ca-2a767fd04c9c",
   "metadata": {},
   "source": [
    "This is my task 2 assignment for D213"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabec2b0-bb9a-4888-ab18-4965490c204b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A1:RESEARCH QUESTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1372df-8849-4256-99d2-d23b235c0c47",
   "metadata": {},
   "source": [
    "> 1.  Summarize one research question that you will answer using neural network models and NLP techniques. Be sure the research question is relevant to a real-world organizational situation and sentiment analysis captured in your chosen data set(s).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9050427d-6f37-4530-86ec-279b9e220408",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4021f93d-d5ab-41c6-b26f-e6f2b9b889b9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A2:OBJECTIVES OR GOALS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd5a77b-49db-4c03-94dd-52656efc5ce4",
   "metadata": {},
   "source": [
    "> 2.  Define the objectives or goals of the data analysis. Be sure the objectives or goals are reasonable within the scope of the research question and are represented in the available data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8e94d1-74e4-4153-96e6-48382a310e3b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce24f009-8824-414c-8b2e-514c70bf7c05",
   "metadata": {
    "tags": []
   },
   "source": [
    "## A3:PRESCRIBED NETWORK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7d2fb5-ea8d-4d56-acd2-8161cae9c6a1",
   "metadata": {},
   "source": [
    "> 3.  Identify a type of neural network capable of performing a text classification task that can be trained to produce useful predictions on text sequences on the selected data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614a4dcd-8ce9-4de2-8acc-d10ca289b4b2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2cef930-ff91-4530-b540-1a4c9cd3a5ed",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B1:DATA EXPLORATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a57274-5940-4681-a905-9982b720ec56",
   "metadata": {},
   "source": [
    "> 1.  Perform exploratory data analysis on the chosen data set, and include an explanation of each of the following elements:\n",
    "> - presence of unusual characters (e.g., emojis, non-English characters)\n",
    "> - vocabulary size\n",
    "> - proposed word embedding length\n",
    "> - statistical justification for the chosen maximum sequence length\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c504e94-6fc9-4fc8-b7f2-5986a3f1518e",
   "metadata": {},
   "source": [
    "To start, we need to impor the libraries that we will be using for this analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b97e91f-8a2f-45eb-b0c7-43614e6c9c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57697e6f-f61c-4824-9ca6-8c6ced04a6c2",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'imdb_labelled.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/b1/vym1dz6s5nd_knffxwjvddwc0000gn/T/ipykernel_48128/4245077012.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimdb_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imdb_labelled.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 932\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    933\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;31m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0;31m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             self.handles = get_handle(  # type: ignore[call-overload]\n\u001b[0m\u001b[1;32m   1217\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    787\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'imdb_labelled.txt'"
     ]
    }
   ],
   "source": [
    "imdb_df = pd.read_csv('imdb_labelled.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ae33b1-166f-45e3-9f55-f218aa12ac22",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B2:TOKENIZATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3138f6-50b5-4d0a-86df-dc96e83d404d",
   "metadata": {},
   "source": [
    "> 2.  Describe the goals of the tokenization process, including any code generated and packages that are used to normalize text during the tokenization process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5e32b2-b07d-41a4-b8c3-733dbc02a3b4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9fbffe99-9591-4b54-ac25-748e042c3367",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B3:PADDING PROCESS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f76e1-8d20-4d0c-8e73-da563b9a5c30",
   "metadata": {},
   "source": [
    "> 3.  Explain the padding process used to standardize the length of sequences. Include the following in your explanation:\n",
    "> - if the padding occurs before or after the text sequence\n",
    "> - a screenshot of a single padded sequence\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8db2c-6ea7-4ee1-bb77-816ba51376eb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f170c24-97c2-435a-a8e4-97a83db002f5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B4:CATEGORIES OF SENTIMENT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8b5b09-472b-4d03-bc10-a902f34bf6fd",
   "metadata": {},
   "source": [
    "> 4.  Identify how many categories of sentiment will be used and an activation function for the final dense layer of the network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4411af-6a7e-4872-ac60-5f8848665006",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e099a3e2-934f-4bc9-9a18-b720f7e78bdd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B5:STEPS TO PREPARE THE DATA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b2136b-6859-4293-88df-51cf8d20b039",
   "metadata": {},
   "source": [
    "> 5.  Explain the steps used to prepare the data for analysis, including the size of the training, validation, and test set split (based on the industry average).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b66b934-e864-4e60-a364-5a9464a90bce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "921eaa05-9e25-4c6e-8b6b-d306bcc0de99",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B6:PREPARED DATA SET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e799b73-9b73-43d5-bc2c-6f20e7a02986",
   "metadata": {},
   "source": [
    "> 6.  Provide a copy of the prepared data set.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cbcb9-d1ec-40da-a03f-65adfd677c23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "038c86a2-3474-4e6c-8628-84fe83cdaf3e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## C1:MODEL SUMMARY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e3c334-482a-4325-89e7-696a7e015d47",
   "metadata": {},
   "source": [
    "> 1.  Provide the output of the model summary of the function from TensorFlow.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "006fc02a-3989-49e0-812c-d64f3eb5cb4e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f42ae92-dad2-4ddf-8da8-598eec86141b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## C2:NETWORK ARCHITECTURE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0cd94d-942e-4552-8e38-bb1abece5258",
   "metadata": {},
   "source": [
    "> 2.  Discuss the number of layers, the type of layers, and the total number of parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2ad306-2886-42e1-9b25-a1d73c5fffd1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "312976bb-6bca-4e6f-8d4a-2d03e044f555",
   "metadata": {
    "tags": []
   },
   "source": [
    "## C3:HYPERPARAMETERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecca55f0-c032-44be-a878-346786ea42c5",
   "metadata": {},
   "source": [
    "> 3.  Justify the choice of hyperparameters, including the following elements:\n",
    "> - activation functions\n",
    "> - number of nodes per layer\n",
    "> - loss function\n",
    "> - optimizer\n",
    "> - stopping criteria\n",
    "> - evaluation metric\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8131dbb5-8801-46ad-a1b2-1ae6801dc951",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7a0c771-a381-4041-b39e-52d624daff66",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D1:STOPPING CRITERIA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e86510-2fb9-40da-8a3b-7780542fe8e1",
   "metadata": {},
   "source": [
    "> 1.  Discuss the impact of using stopping criteria to include defining the number of epochs, including a screenshot showing the final training epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324da63-0d2b-4c17-a371-4b890cd1d355",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97ddf3c-5f20-456b-a3f3-1fa762870a74",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D2:FITNESS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927515c7-6de5-4685-a557-5e721029ebc6",
   "metadata": {},
   "source": [
    "> 2.  Assess the fitness of the model and any actions taken to address overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae7300-c1db-4942-aad3-29f09ae257d3",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "733d5e65-1701-4333-b559-14b6e20e5a03",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D3:TRAINING PROCESS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388d8784-3372-4f60-861a-81dd3dd658d8",
   "metadata": {},
   "source": [
    "> 3.  Provide visualizations of the modelâ€™s training process, including a line graph of the loss and chosen evaluation metric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3abc70d-4fdb-4e50-a66d-1dfe75a45dd0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8a99a2e-59e4-4ce5-9b86-8120c7c9a0e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## D4:PREDICTIVE ACCURACY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aaec8f1-ffd7-4f01-907b-6d071bfd5afd",
   "metadata": {},
   "source": [
    "> 4.  Discuss the predictive accuracy of the trained network using the chosen evaluation metric from part D3.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76dd4b34-818e-4e56-9307-fe862dbd2889",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6132fcf5-41b7-4ddb-aeda-a4a3e1bb8805",
   "metadata": {
    "tags": []
   },
   "source": [
    "## F:FUNCTIONALITY\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd4206b-b5f7-4828-8696-8e0813de7609",
   "metadata": {},
   "source": [
    "> F.  Discuss the functionality of your neural network, including the impact of the network architecture.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca652aa-faf9-45c8-baf3-2d908f04be3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee53c7f8-1331-4c6b-af6b-06b176211962",
   "metadata": {
    "tags": []
   },
   "source": [
    "## G:RECOMMENDATIONS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c4566-f16b-4f8c-9213-c364aaa8c024",
   "metadata": {},
   "source": [
    "> G.  Recommend a course of action based on your results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73761981-84fc-4ee5-a46c-28a118e9adea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9740a77-5629-497f-be7e-8be8d51889be",
   "metadata": {
    "tags": []
   },
   "source": [
    "## I:SOURCES FOR THIRD-PARTY CODE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b81a091-88b9-4516-93c0-282fe85deaae",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84b115d0-041b-451c-af8b-87d4da4eef83",
   "metadata": {
    "tags": []
   },
   "source": [
    "## J:SOURCES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371daaa0-a823-4e19-bf87-c3db26809eb4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
